# -*- coding: utf-8 -*-
"""NaiveBayes.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tu2b3JA3D0fJmicY2uCyzPhT2ULUn6Mt
"""

import pandas as pd
import numpy as np


# Load the dataset
df = pd.read_csv('play_tennis.csv')
df = df.drop('day', axis=1) # Drop the 'day' column

class NaiveBayesClassifier:
    def __init__(self):
        self.class_priors_ = None
        self.feature_probs_ = None
        self.classes_ = None
        
    def fit(self, X, y):
      # Calculate the prior probability of each class
      class_priors = {}
      total_instances = len(X)
      for c in y.unique():
          instances_in_class = len(X[y == c])
          class_priors[c] = np.log((instances_in_class) / (total_instances))

      # Calculate the conditional probability of each feature given each class
      feature_probs = {}
      for c in y.unique():
          class_instances = X[y == c]
          total_instances_in_class = len(class_instances)
          feature_probs[c] = {}
          for feature in X.columns:
              feature_probs[c][feature] = np.log(class_instances[feature].value_counts(normalize=True))
                                          

      self.class_priors_ = class_priors
      self.feature_probs_ = feature_probs
      self.classes_ = y.unique()


        
    def predict(self, X):
      y_pred = []
      for _, instance in X.iterrows():
          scores = {c: self.class_priors_[c] for c in self.classes_}
          for feature, value in instance.items():
              for c in self.classes_:
                  if value in self.feature_probs_[c][feature]:
                      scores[c] += self.feature_probs_[c][feature][value] 
          y_pred.append(max(scores, key=scores.get))
          print('Instance:', instance.tolist(), '\nProbabilities:', {k: np.exp(v) for k, v in scores.items()})
      return y_pred

X = df.drop('play', axis=1)
y = df['play']
    
# Fit the model
my_model = NaiveBayesClassifier()
my_model.fit(X, y)



# Test the model on a new instance
x_new = pd.DataFrame({
    'outlook': ['Sunny'],
    'temp': ['Cool'],
    'humidity': ['High'],
    'wind': ['Strong']
    })

my_model.predict(x_new)

import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import CategoricalNB

# Load the dataset
df = pd.read_csv('play_tennis.csv')
df = df.drop('day', axis=1) # Drop the 'day' column


# separate the target variable from the input features
# Split the data into features and labels
X = df.drop('play', axis=1)
y = df['play']

# encode the categorical variables as integers using label encoding
encoder = LabelEncoder()
X = X.apply(encoder.fit_transform)
# create the CategoricalNB classifier object
clf = CategoricalNB()

# fit the classifier to the data
clf.fit(X.values, y)

# define a new data point to be predicted {'outlook': ['Sunny'],'temp': ['Cool'],'humidity': ['High'],'wind': ['Strong']}
new_data = np.array([[2, 0, 0, 0]])

# make a prediction for the new data point
prediction = clf.predict(new_data)

# print the predicted value
print(prediction[0])